<document xmlns="http://cnx.rice.edu/cnxml">
  <title>Informal Fallacies</title>
  <metadata xmlns:md="http://cnx.rice.edu/mdml">
    <md:title>Informal Fallacies</md:title>
    <md:content-id>m00030</md:content-id>
    <md:uuid>1ecedac5-43f3-465e-a7ab-83e36b9225a9</md:uuid>
  </metadata>
  <content>
    <section class="learning-objectives" id="sect-00001">
<title>Learning Objectives</title>
<para id="para-00001">By the end of this section, you will be able to:</para>
<list id="list-00001">
<item>Explain the four general categories of informal fallacies.</item>
<item>Classify fallacies by general category.</item>
<item>Identify fallacies in ordinary language.</item>
</list>
</section>
<para id="para-00002">Reasoning can go wrong in many ways. When the form of an argument is problematic, it is called a <emphasis effect="italics">formal</emphasis> <term id="term-00001">fallacy</term>. Mistakes in reasoning are not usually caused by the structure of the argument. Rather, there is usually a problem in the relationship between the evidence given in the premises and the conclusion. Take the following example:</para>
<quote id="quote-00001">
<para id="para-00003">I don’t think Ms. Timmons will make a good mayor. I’ve got a bad feeling about her. And I’ve heard she’s not a Christian. Furthermore, the last time we had a female mayor, the city nearly went bankrupt. Don’t vote for Ms. Timmons.</para>
</quote>
<para id="para-00004">Notice that to assess the above argument, you have must think about whether the reasons offered function <emphasis effect="italics">as evidence</emphasis> for the conclusion that Ms. Timmons would be a bad mayor. This assessment requires background knowledge about the world. Does belonging to a specific religion have any bearing on one’s qualification for mayor? Is there any credible connection between a mayor’s gender and the likelihood that person will cause a bankruptcy? If the reasons are not adequate support for the conclusion, then the reasoner commits an informal fallacy. In the above argument, none of the reasons offered support for the conclusion. In fact, each reason commits a different fallacy. The first reason is based on an appeal to emotion, which is not relevant. The second reason points to a characteristic (religion) that is irrelevant in judging competency, and the third reason creates a spurious connection between the candidate and a previous female mayor, putting them both in the same failed category based solely on the fact that they share the same gender.</para>
<para id="para-00005">There are many specific <emphasis effect="italics">types</emphasis> of <term class="no-emphasis" id="term-00002">informal fallacies</term>, but most can be sorted into four general <emphasis effect="italics">categories</emphasis> according to how the reasoning fails. These categories show how reasoning can go wrong and serve as warnings for what to watch out for in arguments. They are (1) fallacies of relevance, (2) fallacies of weak induction, (3) fallacies of unwarranted assumption, and (4) fallacies of diversion.</para>
<note class="philo-connections" id="note-00001">
<para id="para-00006">See <link document="m00008">Overcoming Cognitive Biases in Chapter 2 (2.2)</link> and <link target-id="sect-00009" document="m00007">The Substitution Heuristic in Chapter 2 (2.2.1.2)</link>.</para>
</note>
<section id="sect-00002">
<title>Fallacies of Relevance</title>
<para id="para-00007">In <term class="no-emphasis" id="term-00003">fallacies of relevance</term>, the arguer presents evidence that is not relevant for logically establishing their conclusion. The reason why fallacies of relevance stick around is because the evidence <emphasis effect="italics">seems</emphasis> relevant—meaning it <emphasis effect="italics">feels</emphasis> relevant. Fallacies of relevance prey on our likes and dislikes. Indeed, the very first fallacy of relevance is called “appeal to emotion.”</para>
<section id="sect-00003">
<title>Appeal to Emotion</title>
<para id="para-00008"><term class="no-emphasis" id="term-00004">Emotional appeals</term> can target any number of emotions—from fear to pity and from love and compassion to hate and aversion. For the most part, appeals to emotion of any kind are not relevant for establishing the conclusion. Here’s an example:</para>
<quote id="quote-00002">
<para id="para-00009">I know the allegations against the governor seem serious. However, he’s in his 80s now, and he fought for our country in the Korean War, earning a Purple Heart. We don’t want to put an elderly veteran through the ordeal of a trial. I urge you to drop the charges.</para>
</quote>
<para id="para-00010">In this example, the arguer appeals to our feelings of pity and compassion and to our positive feelings about the governor. We might admire the governor for his military service and feel sympathy for his advanced age. But are our feelings relevant in making the decision about whether to drop criminal charges? Notice that the arguer says nothing about the content of the charges or about whether the governor is innocent or guilty. Indeed, the arguer says absolutely nothing <emphasis effect="italics">that’s relevant to the conclusion</emphasis>. How we feel about somebody is not a logical determinant to use in judging guilt or innocence.</para>
</section>
<section id="sect-00004">
<title>Ad Hominem Attacks</title>
<para id="para-00011">The <term class="no-emphasis" id="term-00005">ad hominem attack</term> is most often committed by a person who is arguing <emphasis effect="italics">against</emphasis> some other person’s position. “Ad hominem” in Latin means “toward the man.” It is so named because when someone commits this fallacy, the reasons they give for their conclusion concern the characteristics of the person they are arguing against rather than that person’s position. For example, the arguer may verbally attack the person by making fun of their appearance, intelligence, or character; they can highlight something about the person’s circumstances like their job or past; or they can insinuate that the person is a hypocrite.</para>
<para id="para-00012">You may wonder why such arguments are effective, and one reason is sloppy associative reasoning, wherein we problematically assume that characteristics held by an arguer will be transferred to their argument. Another related reason is that too often we allow ourselves to be ruled by emotion rather than reason. If we are made to feel negatively toward a person, those feelings can cloud assessment of their arguments. Consider the following example:</para>
<quote id="quote-00003">
<para id="para-00013">My fellow councilwoman has argued for the city solar project. But what she failed to mention was that she has been arrested twice—once for protesting during the Vietnam War and another time for protesting the 2003 invasion of Iraq. She’s a traitor and a liar. Any project she espouses is bad for the city.</para>
</quote>
<para id="para-00014">This is clearly an ad hominem attack. The arguer wants to undermine the councilwoman’s position by making us feel negatively toward her. The fact that a person engaged in protests in the past has no bearing on their arguments for an energy project. Furthermore, the arguer goes on to call the councilwoman a <emphasis effect="italics">traitor</emphasis> and a <emphasis effect="italics">liar</emphasis> and offers no evidence. Attaching negative labels to people is one way to manipulate an audience’s emotions.</para>
<para id="para-00015">There are other types of ad hominem attacks, and the most successful is probably the one called <emphasis effect="italics">tu quoque</emphasis>, which means “you too” in Latin. When someone commits a <emphasis effect="italics">tu quoque</emphasis> ad hominem fallacy, they attempt to undermine a person’s argument by pointing to real or perceived hypocrisy on the part of the person. They assert or imply that their opponent, in the past or currently, has done or said things that are inconsistent with their current argument. Often <emphasis effect="italics">tu quoque</emphasis> is used as a defensive maneuver. Take the example of a teenager whose father just caught her smoking cigarettes and reprimanded her. If she knows that her father smoked when he was her age, her defensive response will be “You did it too!” She is likely to think he is a hypocrite who should not be heeded. However, the daughter reasons poorly. First, a person’s actions have no bearing on the strength of their arguments or the truth of their claims (unless, of course, the person’s arguments are about their own actions). That her father smoked in the past (or smokes currently) has no bearing on whether smoking is in fact dangerous. Smoking does not suddenly cease to be dangerous because the person explaining the dangers of smoking is a smoker.</para>
<para id="para-00016">You might think, however, that we should not trust the reasoning of hypocrites because hypocrisy is a sign of untrustworthiness, and untrustworthy people often say false things. But remember that there is a difference between a truth analysis and a logical analysis. <emphasis effect="italics">If</emphasis> smoking has bad consequences on health and development, <emphasis effect="italics">then</emphasis> that counts as a good reason for the father to not allow his daughter to smoke. But interestingly, some cases of perceived hypocrisy make the supposed hypocrite more trustworthy rather than less. And the smoking example is one such case. Of all the people who might be able to speak of the dangers of picking up a smoking habit at a young age, the father, who became addicted to cigarettes in his teenage years, is a good source. He speaks from experience, which is a second reason the daughter reasons incorrectly in thinking she should not listen to him because he was or is a smoker.</para>
<para id="para-00017">Let’s take a different scenario. Suppose a married person argues that it is immoral to cheat on one’s spouse, but you know he has a mistress. As much as you may hate it, his status as a cheater in not relevant to assessing his argument. You might infer from his hypocrisy that he does not believe his own arguments or perhaps that he suffers guilt about his actions but cannot control his cheating behavior. Nonetheless, whatever the cheater believes or feels is simply <emphasis effect="italics">not relevant to determining whether his argument is good</emphasis>. To think that whether a person believes an argument affects the truth of that argument is tantamount to thinking that if you believe X, the belief itself is more likely to make X happen or make X true. But such an approach is magical thinking, not logic or reason.</para>
</section>
</section>
<section id="sect-00005">
<title>Fallacies of Weak Induction</title>
<para id="para-00018">The <term class="no-emphasis" id="term-00006">fallacies of weak induction</term> are mistakes in reasoning in which a person’s evidence or reasons are too weak to firmly establish a conclusion. The reasoner uses relevant premises, but the evidence contained therein is weak or defective in some way. These errors are errors of induction. When we inductively reason, we gather evidence using our experience in the world and draw conclusions based on that experience. Earlier in the chapter I used a generalization about the return of the red-winged blackbirds in March. But what if I based my generalization on just two years of experience? Now my conclusion—that the blackbirds return every mid-March—seems much weaker. In such cases, the reasoner uses induction properly by using relevant evidence, but her evidence is simply too weak to support the generalization she makes. An inductive inference may also be weak because it too narrowly focuses on one type of evidence, or the inference may apply to a generalization in the wrong way.</para>
<section id="sect-00006">
<title>Hasty Generalization</title>
<para id="para-00019">A <term id="term-00007">hasty generalization</term> is a fallacy of weak induction in which a person draws a conclusion using too little evidence to support the conclusion. A hasty generalization was made in the red-winged blackbird case above. Here is another example:</para>
<quote id="quote-00004">
<para id="para-00020">Don’t eat at the restaurant. It’s bad. I had lunch there once, and it was awful. Another time I had dinner, and the portions were too small.</para>
</quote>
<para id="para-00021">This person draws the conclusion that the restaurant is bad from two instances of eating there. But two instances are not enough to support such a robust conclusion. Consider another example:</para>
<quote id="quote-00005">
<para id="para-00022">Sixty-five percent of a random poll of 50 registered voters in the state said they would vote for the amendment. We conclude that the state amendment will pass.</para>
</quote>
<para id="para-00023">Fifty voters is not a large enough sample size to draw predictive conclusions about an election. So to say the amendment will pass based on such limited evidence is a hasty generalization. Just how much evidence we need to support a generalization depends upon the conclusion being made. If we already have good reason to believe that the class of entities that is the subject of our generalization are all very similar, then we will not need a very large sample size to make a reliable generalization. For instance, physics tells us that electrons are very similar, so a study drawn from observing just a few electrons may be reasonable. Humans (particularly their political beliefs and behaviors) are not the same, so a much larger sample size is needed to determine political behavior. The fallacy of hasty generalization highlights the empirical nature of induction—we need a basic understanding of the world to know exactly how much evidence is needed to support many of our claims.</para>
</section>
<section id="sect-00007">
<title>Biased Sample</title>
<para id="para-00024">A biased sample has some things in common with a hasty generalization. Consider the following:</para>
<quote id="quote-00006">
<para id="para-00025">Don’t eat dinner at that restaurant. It’s bad. My prayer group has met there once a week for breakfast for the past year, and they overcook their eggs.</para>
</quote>
<para id="para-00026">This seems much better than the restaurant example offered above. If the prayer group has gone to the restaurant once per week for a year, the arguer has more than 50 instances as data. However, notice that the arguer’s evidence concerns <emphasis effect="italics">breakfast</emphasis>, not dinner, and focuses on the eggs. Suppose the restaurant has an entirely different, more expensive dinner menu; then we cannot draw reliable conclusions about the restaurant’s success at dinner. This is an example of a <term id="term-00008">biased sample</term>. With a hasty generalization, the problem is that not enough evidence is used. In a biased sample, the problem is that the evidence used is biased in some way.</para>
</section>
<section id="sect-00008">
<title>Appeal to Ignorance</title>
<para id="para-00027"><term id="term-00009">Appeal to ignorance</term> is another type of fallacy of weak induction. Consider the following line of reasoning:</para>
<quote id="quote-00007">
<para id="para-00028">In my philosophy class, we reviewed all the traditional arguments for the existence of God. All of them have problems. Because no one can prove that God exists, we can only conclude that God doesn’t exist.</para>
</quote>
<para id="para-00029">Notice that the arguer wants to conclude that because we do not have evidence or sufficient arguments for God’s existence, then God cannot exist. In an appeal to ignorance, the reasoner relies on the lack of knowledge or evidence for a thing (our ignorance of it) to draw a definite conclusion about that thing. But in many cases, this simply does not work. The same reasoning can be used to assert that God must exist:</para>
<quote id="quote-00008">
<para id="para-00030">In my philosophy class, we reviewed different arguments against the existence of God. All of them have problems. Because no one can prove that God doesn’t exist, we can only conclude that God exists.</para>
</quote>
<para id="para-00031">Any form of reasoning that allows you to draw contradictory conclusions ought to be suspect. Appeals to ignorance ignore the idea that absence of evidence is not evidence of absence. The fact that we lack evidence for X should not always function <emphasis effect="italics">as evidence</emphasis> that X is false or does not exist.</para>
</section>
<section id="sect-00009">
<title>False Cause Attribution</title>
<para id="para-00032">The fallacy of <term id="term-00010">false cause</term> occurs when a causal relation is assumed to exist between two events or things when it is unlikely that such a causal relationship exists. People often make this mistake when the two events occur together. The phrase “correlation does not equal causation” captures a common critique of this form of false cause reasoning. For example, a person may think that swimsuits cause sunburns because people often get sunburned when wearing swimsuits. There is a correlation between sunburn and swimsuits, but the suits are not a cause of sunburns.</para>
<para id="para-00033">False cause fallacies also occur when a person believes that just because one event occurs after another, the first event is the cause of the second one. This poor form of reasoning, in tandem with confirmation bias, leads to many superstitious beliefs. Confirmation bias is the natural tendency to look for, interpret, or recall information that confirms already-established beliefs or values. For example, some sports fans may notice that their team won sometimes on days when they were wearing a specific item of clothing. They may come to believe that this clothing item is “lucky.” Furthermore, because of confirmation bias, they may remember only instances when the team won when they were wearing that item (and not remember when the team lost when they were also wearing the item). The resulting superstition amounts to believing that wearing a special team jersey somehow <emphasis effect="italics">causes</emphasis> the team to win.</para>
<figure id="fig-00001"><media alt="A box contains the words, correlation does not equal causation."><image mime-type="image/png" src="../../media/PHIL_Figure_05_05_005.png"/></media>
<caption>Correlation Is Not the Same as Causation (attribution: Copyright Rice University, OpenStax, under CC BY 4.0 license)</caption></figure>
<para id="para-00034">In short, as emphasized by Figure 5.5, just because two things are often correlated (connected in that they occur together in time or place) does not mean that a cause-and-effect relationship exists between them.</para>
<note class="philo-connections" id="note-00002">
<para id="para-00035">See Confirmation Bias in Chapter 2 (2.2.2.1).</para>
</note>
</section>
</section>
<section id="sect-00010">
<title>Fallacies of Unwarranted Assumption</title>
<para id="para-00036">Fallacies of unwarranted assumption occur when an argument relies on a piece of information or belief that requires further justification. The category gets its name from the fact that a person <emphasis effect="italics">assumes</emphasis> something <emphasis effect="italics">unwarranted</emphasis> to draw their conclusion. Often the unjustified assumption is only implicit, which can make these types of fallacies difficult to identify.</para>
<section id="sect-00011">
<title>False Dichotomy</title>
<para id="para-00037"><term class="no-emphasis" id="term-00011">False dichotomy</term>, or “false dilemma,” occurs in an argument when a limited number of possibilities are assumed to be the only available options. In the classic variation, the arguer offers two possibilities, shows that the one cannot be true, and then deduces that the other possibility must be true. Here is the form:</para>
<list list-type="enumerated" id="list-00002">
<item>Either A or B must be true.</item>
<item>A is not true.</item>
<item>Therefore, B is true.</item>
</list>
<para id="para-00038">The form itself looks like a good argument—a form of disjunctive syllogism. But a false dichotomy is an <emphasis effect="italics">informal</emphasis> fallacy, and such errors depend upon the content of arguments (their meaning and relation to the world) rather than the form. The problematic assumption occurs in premise 1, where it is assumed that A and B are the <emphasis effect="italics">only</emphasis> options. Here is a concrete example:</para>
<quote id="quote-00009">
<para id="para-00039">A citizen of the United States either loves their country, or they are a traitor. Since you don’t love your country, you are a traitor.</para>
</quote>
<para id="para-00040">The above argument assumes that loving the United States or being a traitor are the only two possible options for American citizens. The argument assumes these options are mutually exclusive (you cannot be both) and jointly exhaustive (you must be one or the other). But this position requires justification. For example, a person can have mixed emotions about their country and <emphasis effect="italics">not</emphasis> be a traitor. False dichotomy is poor reasoning because it artificially limits the available options and then uses this artificial limitation to attempt to prove some conclusion. A false dichotomy may include more than two options. The important thing to remember is a false dichotomy limits options in an argument without justification when there is reason to think there are more options.</para>
</section>
<section id="sect-00012">
<title>Begging the Question</title>
<para id="para-00041"><term id="term-00012">Begging the question</term> occurs when an arguer either assumes the truth of the conclusion they aim to prove in the course of trying to prove it or when an arguer assumes the truth of a contentious claim in their argument. When the former happens, it is sometimes called <emphasis effect="italics">circular reasoning</emphasis>. Here is an example:</para>
<list list-type="enumerated" id="list-00003">
<item>The Bible states that God exists.</item>
<item>The Bible is true because it is divinely inspired.</item>
<item>Therefore, God exists.</item>
</list>
<para id="para-00042">The problematic assumption occurs in premise 2. To say the Bible is “divinely inspired” is to say that it <emphasis effect="italics">is the word of God</emphasis>. But the argument aims to prove that God exists. So premise 2 assumes that God exists in order to prove God exists. This is patently circular reasoning. The name “begging the question” is confusing to some students. One way to think about this fallacy is that <emphasis effect="italics">the question</emphasis> is whatever is at issue in a debate or argument. Here the question is “Does God exist?” To “beg” the question means to assume you already know the answer. The above argument assumes the answer to the question it is supposed to answer.</para>
<para id="para-00043">The name “begging the question” makes more sense for the second form of the fallacy. When a person begs the question in the second sense, they assume the truth of something controversial while trying to prove their conclusion. Here is an example you might be familiar with:</para>
<list list-type="enumerated" id="list-00004">
<item>The intentional killing of an innocent person is murder.</item>
<item>Abortion is the intentional killing of an innocent person.</item>
<item>Therefore, abortion is murder.</item>
</list>
<para id="para-00044">This is a valid argument. Structurally, it uses good logic. However, the argument is an example of begging the question because of premise 2. Much of the debate over abortion revolves around the question of whether a fetus is a person. But premise 2 simply assumes that a fetus is a person, so the argument <emphasis effect="italics">begs the question</emphasis> “Is a fetus a person?”</para>
</section>
</section>
<section id="sect-00013">
<title>Fallacies of Diversion</title>
<para id="para-00045">The final class of informal fallacies is the fallacy of diversion, which usually occurs in contexts where there is an opponent or an audience. In this instance, the arguer attempts to distract the attention of the audience away from the argument at hand. Clearly, the tactic of diverting attention implies that there is someone whose attention can be diverted: either an audience, an opponent, or both.</para>
<section id="sect-00014">
<title>Strawman</title>
<para id="para-00046">Men made of straw can easily be knocked over. Hence, a <term id="term-00013">strawman</term> occurs when an arguer presents a weaker version of the position they are arguing against to make the position easier to defeat. The arguer takes their opponent’s argument, repackages it, and defeats this new version of the argument rather than their opponent’s actual position. If the audience listening to or reading the argument is not careful, they won’t notice this move and believe that the opponent’s original position has been defeated. Usually when a strawman is created, the misrepresented position is made more extreme. Here is an example:</para>
<quote id="quote-00010">
<para id="para-00047"><emphasis effect="bold">Senator:</emphasis> It is important to provide a path to citizenship for undocumented immigrants who were brought here as children. It is not their fault they were brought here. For most, this is the only country they have ever known. Many have become productive members of society. Some undocumented immigrants even own businesses. It would be a loss to our country to expel these persons.</para>
<para id="para-00048"><emphasis effect="bold">Opponent:</emphasis> Clearly, we can reject the Senator’s position on immigration, which is tantamount to condoning open borders. We cannot just open up the borders and let every person into the country who wants to come in. We will get inundated by millions of people. We simply don’t have the amount of housing or job infrastructure to support millions of people pouring in.</para>
</quote>
<para id="para-00049">The opponent misrepresents the senator as being in favor of opening borders to all immigrants and then argues against that manufactured position—a classic strawman move. The senator’s original argument narrowly focused on a group of immigrants already living in the United States. The repackaged argument is much easier to defeat than the senator’s actual argument since few people are in favor of lifting all restrictions on US borders.</para>
</section>
<section id="sect-00015">
<title>Red Herring</title>
<para id="para-00050">A <term class="no-emphasis" id="term-00014">red herring fallacy</term> is like a strawman, except the arguer completely ignores their opponent’s position and simply changes the subject. The arguer diverts the attention of the audience to a new subject. A red herring is a smelly smoked fish that was used to train hunting dogs to track smells by dragging this fish along a path as practice. So the fallacy gets its name because it means to trick people into following a different path of reasoning than the one at hand. You may wonder how a person can get away with simply changing the subject. Successful use of the red herring usually involves shifting the subject to something tangentially related. Here is an example:</para>
<quote id="quote-00011">
<para id="para-00051">My daughter wants me to exercise more. She said she is worried about my health. She showed me research about the effects of excess weight on mobility and joints for people my age and older. She suggested I start biking with her. But bicycles are expensive. And it is dangerous to ride bicycles on a busy road. Furthermore, I do not have a place to store a bicycle.</para>
</quote>
<para id="para-00052">This arguer first summarizes the daughter’s position that they ought to exercise more. But then they take the suggestion of bicycling and veer off topic (getting more exercise) to the feasibility of cycling instead. The comments on bicycling in no way address the daughter’s general conclusion that the arguer needs to exercise more. Because the argument changes the subject, it is a red herring.</para>
<note class="think-philosopher" id="note-00003">
<para id="para-00053">In this activity, you will identify the type of fallacy each statement demonstrates.</para>
<media alt="atoms_isotopes"><iframe width="660" height="371.4" src="../../media/Interactive/031221_opx_philo_05_interactive04_drag_drop_1c/index.html"/></media>
</note>
</section>
</section>

<section class="summary" id="sect-00016">
<title/>
<para id="para-00054">A fallacy is a poor form of reasoning. Fallacies that cannot be reduced to the structure of an argument are called informal fallacies. There are many types of informal fallacies, which can be sorted into four general <emphasis effect="italics">categories</emphasis> according to how the reasoning fails. These categories are fallacies of relevance, fallacies of weak induction, fallacies of unwarranted assumption, and fallacies of diversion. A fallacy of relevance occurs when the arguer presents evidence that is not relevant for logically establishing their conclusion. The fallacies of weak induction occur when the evidence used is relevant but is too weak to support the desired conclusion. The fallacies of unwarranted assumption occur when an argument assumes, as evidence, some reason that requires further justification. The fallacies of diversion occur when the arguer attempts to distract the attention of the audience from the argument at hand.</para>
</section>

<section class="review-questions" id="sect-00017">
<title/>
<exercise id="exer-00001">
<problem id="prob-00001">
<para id="para-00055"><link class="os-embed" url="exercise/PH_Ch5-Sec5_RQ1"/></para>
</problem>
</exercise>
<exercise id="exer-00002">
<problem id="prob-00002">
<para id="para-00056"><link class="os-embed" url="exercise/PH_Ch5-Sec5_RQ2"/></para>
</problem>
</exercise>
<exercise id="exer-00003">
<problem id="prob-00003">
<para id="para-00057"><link class="os-embed" url="exercise/PH_Ch5-Sec5_RQ3"/></para>
</problem>
</exercise>
<exercise id="exer-00004">
<problem id="prob-00004">
<para id="para-00058"><link class="os-embed" url="exercise/PH_Ch5-Sec5_RQ4"/></para>
</problem>
</exercise>
</section>

<section class="further-reading" id="sect-00018">
<title>Suggested Readings</title>
<para id="para-00059">Russell, Bertrand. 1912. “The Value of Philosophy.” In <emphasis effect="italics">The Problems of Philosophy</emphasis>, 237–250. London: Williams and Norgate. https://www.google.com/books/edition/The_Problems_of_Philosophy/F3CABBiwm6wC?hl=en&amp;gbpv=1</para>
</section>

<section class="references" id="sect-00019">
<title>References</title>
<para id="para-00060">Aristotle. <emphasis effect="italics">Metaphysics</emphasis>. In <emphasis effect="italics">Aristotle in 23 Volumes</emphasis>. Translated by Hugh Tredennick. Cambridge, MA: Harvard University Press; London: William Heinemann Ltd., 1933, 1989. http://www.perseus.tufts.edu/hopper/text?doc=Perseus%3Atext%3A1999.01.0052%3Abook%3D4%3Asection%3D1005b</para>
<para id="para-00061">Aristotle. <emphasis effect="italics">On Interpretation.</emphasis> Translated by Jean T. Oesterle. Milwaukee: Marquette University Press, 1962. https://www.google.com/books/edition/On_Interpretation/vXbkAAAAMAAJ?hl=en&amp;gbpv=1</para>
<para id="para-00062">Gillon, Brendan. “Logic in Classical Indian Philosophy.” <emphasis effect="italics">The Stanford Encyclopedia of Philosophy</emphasis>. Updated March 10, 2021. https://plato.stanford.edu/archives/spr2021/entries/logic-india/</para>
<para id="para-00063">Gottlieb, Paula. “Aristotle on Non-contradiction.” <emphasis effect="italics">The Stanford Encyclopedia of Philosophy</emphasis>. Updated March 6, 2019. https://plato.stanford.edu/archives/spr2019/entries/aristotle-noncontradiction/</para>
<para id="para-00064">Hume, David. (1748, 1777) 2011. <emphasis effect="italics">An Inquiry Concerning Human Understanding, and Concerning the Principles of Morals.</emphasis> Project Gutenberg. https://www.gutenberg.org/files/9662/9662-h/9662-h.htm</para>
<para id="para-00065">Mark, Joshua J. “The Vedas.” <emphasis effect="italics">World History Encyclopedia</emphasis>. June 9, 2020. https://www.worldhistory.org/The_Vedas/</para>
<para id="para-00066">MacFarlane, John Gordon. 2002. “Frege, Kant, and the Logic in Logicism.” <emphasis effect="italics">The Philosophical Review</emphasis> 111, no. 1: 25–65. doi:10.1215/00318108-111-1-25</para>
<para id="para-00067">NASA. n.d. “NASA Spinoff.” NASA Technology Transfer Program. Accessed June 24, 2021. https://spinoff.nasa.gov/</para>
<para id="para-00068">Plato. <emphasis effect="italics">Meno</emphasis>. In <emphasis effect="italics">Plato Complete Works</emphasis>. Edited by John M. Cooper. Indianapolis: Hackett Publishing Company, 1997.</para>
<para id="para-00069">Plato. <emphasis effect="italics">Phaedrus</emphasis>. In <emphasis effect="italics">Plato Complete Works</emphasis>. Edited by John M. Cooper. Indianapolis: Hackett Publishing Company, 1997.</para>
<para id="para-00070">Russell, Bertrand. 1912. <emphasis effect="italics">The Problems of Philosophy</emphasis>. London: Williams and Norgate. https://www.google.com/books/edition/The_Problems_of_Philosophy/F3CABBiwm6wC?hl=en&amp;gbpv=1</para>
<para id="para-00071">Smith, Robin. “Aristotle’s Logic.” <emphasis effect="italics">The Stanford Encyclopedia of Philosophy</emphasis>. Updated February 17, 2017. https://plato.stanford.edu/archives/fall2020/entries/aristotle-logic/</para>
<para id="para-00072">Spade, Paul Vincent, and Claude Panaccio. “William of Ockham.” <emphasis effect="italics">The Stanford Encyclopedia of Philosophy.</emphasis> Updated March 5, 2019. https://plato.stanford.edu/archives/spr2019/entries/ockham/</para>
</section>
</content>
<glossary>
<definition id="def-00001"><term>Fallacy</term> <meaning>a poor form of reasoning.</meaning></definition>
<definition id="def-00002"><term>Fallacy of diversion</term> <meaning>a general category of informal fallacies in which an arguer presents evidence that functions to divert the attention of the audience from the current subject of argument.</meaning></definition>
<definition id="def-00003"><term>Fallacy of relevance</term> <meaning>a general category of informal fallacies in which an arguer relies on reasons that are not relevant for establishing a conclusion.</meaning></definition>
<definition id="def-00004"><term>Fallacy of unwarranted assumption</term> <meaning>a general category of informal fallacies in which an arguer implicitly or explicitly relies on reasons that require further justification.</meaning></definition>
<definition id="def-00005"><term>Fallacy of weak induction</term> <meaning>a general category of informal fallacies in which an arguer’s evidence or reasons are too weak to firmly establish their conclusion.</meaning></definition>
</glossary>
</document>